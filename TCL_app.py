
import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from scipy import stats
import seaborn as sns

# ConfiguraciÃ³n de la pÃ¡gina
st.set_page_config(
    page_title="Teorema Central del LÃ­mite",
    page_icon="ğŸ“Š",
    layout="wide"
)

# Configurar el estilo de matplotlib
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

def main():
    st.title("ğŸ“Š Teorema Central del LÃ­mite: AproximaciÃ³n intuitiva e interactiva")
    st.markdown("---")
    
    # Crear pestaÃ±as
    tab1, tab2, tab3 = st.tabs([
        "ğŸ² MÃ©todo 1: Muestreo Real (Medias Muestrales)",
        "ğŸ“ˆ MÃ©todo 2: Enfoque de Taleb", 
        "ğŸ¤” ReflexiÃ³n y ExplicaciÃ³n"
    ])
    
    with tab1:
        sampling_method()
    
    with tab2:
        taleb_method()
    
    with tab3:
        comparison_explanation()

    st.text ('Creado para la cÃ¡tedra MÃ©todos Cuantitativos en ArqueologÃ­a 2025')

def taleb_method():
    st.header("ğŸ² MÃ©todo 2: Enfoque de Taleb (Suma de Distribuciones)")
    
    st.markdown("""
    **Â¿QuÃ© estamos haciendo aquÃ­?**
    Comenzamos con una distribuciÃ³n uniforme (plana, probabilidad igual en todas partes). 
    Cada vez que sumamos otra distribuciÃ³n uniforme a sÃ­ misma, el resultado se vuelve mÃ¡s "acampanado".
    Esta idea estÃ¡ inspirada en el mooc sobre probabilidad de Nassim Taleb https://youtu.be/bfM9efdStN8?si=TCVAD1uxm8rjzCep
    """)
    
    # Controles
    col1, col2 = st.columns([1, 2])
    
    with col1:
        n_sumas = st.slider(
            "NÃºmero de sumas de la distribuciÃ³n uniforme:",
            min_value=1,
            max_value=10,
            value=1,
            key="taleb_slider"
        )
        
        st.markdown(f"**Actualmente mostrando:** Suma de {n_sumas} distribuciÃ³n(es) uniforme(s)")
    
    with col2:
        # Generar y mostrar la distribuciÃ³n
        fig, ax = plt.subplots(figsize=(10, 6))
        
        if n_sumas == 1:
            # DistribuciÃ³n uniforme simple
            x = np.linspace(1, 10, 100)
            y = np.ones_like(x) * 0.111  # 1/9 para distribuciÃ³n uniforme(1,10)
            ax.plot(x, y, linewidth=3, label='DistribuciÃ³n Uniforme')
            ax.fill_between(x, y, alpha=0.3)
        else:
            # Simular suma de distribuciones uniformes
            n_samples = 10000
            sumas = np.zeros(n_samples)
            
            for _ in range(n_sumas):
                sumas += np.random.uniform(1, 10, n_samples)
            
            # Crear histograma
            ax.hist(sumas, bins=50, density=True, alpha=0.7, 
                   label=f'Suma de {n_sumas} Uniformes', edgecolor='black')
            
            # Superponer distribuciÃ³n normal teÃ³rica
            media_teorica = n_sumas * 5.5
            var_teorica = n_sumas * (81/12)  # varianza de uniforme(1,10)
            std_teorica = np.sqrt(var_teorica)
            
            x_normal = np.linspace(sumas.min(), sumas.max(), 100)
            y_normal = stats.norm.pdf(x_normal, media_teorica, std_teorica)
            ax.plot(x_normal, y_normal, 'r--', linewidth=2, 
                   label='DistribuciÃ³n Normal TeÃ³rica')
        
        ax.set_xlabel('Valor')
        ax.set_ylabel('Densidad de Probabilidad')
        ax.set_title(f'Suma de {n_sumas} DistribuciÃ³n(es) Uniforme(s)')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        st.pyplot(fig)
    
    # ExplicaciÃ³n
    st.info("""
    **ğŸ’¡ ObservaciÃ³n clave:** Nota cÃ³mo la distribuciÃ³n se vuelve mÃ¡s "normal" (acampanada) 
    a medida que sumas mÃ¡s distribuciones uniformes. Esto demuestra el principio matemÃ¡tico 
    subyacente: cuando sumas variables aleatorias independientes, el resultado tiende hacia 
    una distribuciÃ³n normal.
    """)

def sampling_method():
    st.header("ğŸ“ˆ MÃ©todo 1: Muestreo Real (Medias Muestrales)")
    
    st.markdown("""
    **Â¿QuÃ© estamos haciendo aquÃ­?**
    Tomamos repetidamente muestras de nuestra poblaciÃ³n uniforme y calculamos sus medias. 
    Aunque las muestras individuales varÃ­an, Â¡la **distribuciÃ³n de estas medias muestrales** 
    se vuelve normal!
    """)
    
    # Controles
    col1, col2 = st.columns(2)
    
    with col1:
        tamaÃ±o_muestra = st.selectbox(
            "TamaÃ±o de cada muestra:",
            options=[2, 5, 10, 20, 50],
            index=2
        )
        
        n_muestras = st.slider(
            "NÃºmero de muestras a tomar:",
            min_value=10,
            max_value=300,
            value=100,
            step=10
        )
    
    with col2:
        if st.button("ğŸ¯ Tomar Muestras", type="primary"):
            # Generar muestras
            medias_muestrales = []
            
            for _ in range(n_muestras):
                muestra = np.random.uniform(1, 10, tamaÃ±o_muestra)
                medias_muestrales.append(np.mean(muestra))
            
            # Guardar en session state
            st.session_state.medias_muestrales = medias_muestrales
            st.session_state.tamaÃ±o_muestra = tamaÃ±o_muestra
            st.session_state.n_muestras = n_muestras
    
    # Mostrar resultados si existen
    if 'medias_muestrales' in st.session_state:
        medias = st.session_state.medias_muestrales
        
        # Crear grÃ¡ficos lado a lado
        col1, col2 = st.columns(2)
        
        with col1:
            # PoblaciÃ³n original
            fig1, ax1 = plt.subplots(figsize=(8, 6))
            x_uniform = np.linspace(1, 10, 100)
            y_uniform = np.ones_like(x_uniform) * 0.111
            ax1.plot(x_uniform, y_uniform, linewidth=3, color='red')
            ax1.fill_between(x_uniform, y_uniform, alpha=0.3, color='red')
            ax1.set_xlabel('Valor')
            ax1.set_ylabel('Densidad de Probabilidad')
            ax1.set_title('PoblaciÃ³n Original (Uniforme)')
            ax1.grid(True, alpha=0.3)
            ax1.set_ylim(0, 0.15)
            st.pyplot(fig1)
        
        with col2:
            # DistribuciÃ³n de medias muestrales
            fig2, ax2 = plt.subplots(figsize=(8, 6))
            ax2.hist(medias, bins=30, density=True, alpha=0.7, 
                    color='teal', edgecolor='black')
            
            # Superponer distribuciÃ³n normal teÃ³rica
            media_poblacion = 5.5
            error_estandar_teorico = np.sqrt(81/12) / np.sqrt(st.session_state.tamaÃ±o_muestra)
            
            x_normal = np.linspace(min(medias), max(medias), 100)
            y_normal = stats.norm.pdf(x_normal, media_poblacion, error_estandar_teorico)
            ax2.plot(x_normal, y_normal, 'r--', linewidth=2, 
                    label='Normal TeÃ³rica')
            
            ax2.set_xlabel('Media Muestral')
            ax2.set_ylabel('Densidad')
            ax2.set_title('DistribuciÃ³n de Medias Muestrales')
            ax2.legend()
            ax2.grid(True, alpha=0.3)
            st.pyplot(fig2)
        
        # EstadÃ­sticas
        st.subheader("ğŸ“Š EstadÃ­sticas")
        
        col1, col2, col3, col4 = st.columns(4)
        
        media_poblacion = 5.5
        promedio_medias = np.mean(medias)
        error_estandar_teorico = np.sqrt(81/12) / np.sqrt(st.session_state.tamaÃ±o_muestra)
        error_estandar_real = np.std(medias)
        
        with col1:
            st.metric("Media Poblacional", f"{media_poblacion:.2f}")
        
        with col2:
            st.metric("Promedio de Medias Muestrales", f"{promedio_medias:.3f}")
        
        with col3:
            st.metric("Error EstÃ¡ndar TeÃ³rico", f"{error_estandar_teorico:.3f}")
        
        with col4:
            st.metric("Error EstÃ¡ndar Real", f"{error_estandar_real:.3f}")
        
        # ExplicaciÃ³n de resultados
        st.success(f"""
        **ğŸ¯ Veamos quÃ© pasÃ³** con {st.session_state.n_muestras} muestras de tamaÃ±o {st.session_state.tamaÃ±o_muestra}:
        
        - El promedio de las medias muestrales ({promedio_medias:.3f}) estÃ¡ muy cerca de la media poblacional (5.5)
        - El error estÃ¡ndar real ({error_estandar_real:.3f}) coincide con el teÃ³rico ({error_estandar_teorico:.3f})
        - La distribuciÃ³n de medias muestrales es aproximadamente normal, Â¡aunque la poblaciÃ³n es uniforme!
        """)

def comparison_explanation():
    st.header("ğŸ¤” Â¿QuÃ© vemos en estas simulaciones?")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ² Â¿CÃ³mo se comporta el promedio de las medias?")
        st.markdown("""
        - Es relativamente estable con distribuciones poblacionales uniformes
        - Es levemente sensible al tamaÃ±o de la muestra
        - Es levemente sensible a la cantidad de muestras
        """)
    
    with col2:
        st.subheader("ğŸ“ˆ QuÃ© pasa con el error?")
        st.markdown("""
        - Es muy sensible al tamaÃ±o de las muestras
        - Tiene baja sensibilidad a la cantidad de muestras despuÃ©s de cierto umbral (> 10)
        - El error teÃ³rico se acerca al real con tamaÃ±os de muestras > 30  
        """)
    
    st.markdown("---")
    
    st.subheader("ğŸ¯ Implicaciones para en la prÃ¡ctica")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.success("""
        **Â¿Por quÃ© es importante?**
        - Podemos hacer inferencias confiables de muestras pequeÃ±as
        - Las medias muestrales son mÃ¡s estables que observaciones individuales
        - Justifica el uso de pruebas estadÃ­sticas
        - Base de intervalos de confianza
        """)
    
    with col2:
        st.warning("""
        **Condiciones importantes:**
        - Muestras deben ser aleatorias
        - Observaciones independientes
        - TamaÃ±o de muestra suficiente (n â‰¥ 30 como regla general)
        - Funciona sin importar la forma de la poblaciÃ³n original
        """)
    
    st.markdown("---")
    
    st.subheader("ğŸ§  Ejercicio de ReflexiÃ³n")
    
    with st.expander("ğŸ’­ Preguntas para discutir en clase"):
        st.markdown("""
        1. **Â¿QuÃ© pasarÃ­a si tomÃ¡ramos muestras de tamaÃ±o 1?** 
           - Pista: La distribuciÃ³n serÃ­a igual a la poblaciÃ³n original
        
        2. **Â¿Por quÃ© las medias muestrales varÃ­an menos que los datos individuales?**
           - Pista: Piensa en el efecto de promediar valores extremos
        
        3. **Â¿FuncionarÃ­a esto con cualquier distribuciÃ³n poblacional?**
           - Pista: Â¡SÃ­! Prueba cambiando la distribuciÃ³n original
        
        """)

if __name__ == "__main__":
    main()